{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEBLe7tAHfFr8yuN6o2kTG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import json\n","import csv\n","\n","def extract_tweet_info_from_json(json_file, csv_file):\n","    with open(json_file, 'r', encoding='utf-8') as file:\n","        data = json.load(file)\n","        with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n","            fieldnames = ['tweet_id', 'username', 'created_at']\n","            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","            writer.writeheader()\n","            for tweet_data in data:\n","                tweet_id = tweet_data['tweet']['id_str']\n","                user_mentions = tweet_data['tweet'].get('entities', {}).get('user_mentions', [])\n","                if user_mentions:\n","                    username = user_mentions[0]['screen_name']\n","                else:\n","                    username = \"N/A\"\n","                created_at = tweet_data['tweet']['created_at']\n","                writer.writerow({'tweet_id': tweet_id, 'username': username, 'created_at': created_at})\n","\n","if __name__ == \"__main__\":\n","    # Replace 'tweets.json' with the path to your JSON archive file\n","    json_file = 'data.json'\n","    # Replace 'tweet_info.csv' with the desired name for your CSV file\n","    csv_file = 'tweet_IDs.csv'\n","    extract_tweet_info_from_json(json_file, csv_file)\n","    print(\"Data has been written to\", csv_file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvmYRGJooyuj","executionInfo":{"status":"ok","timestamp":1709518401921,"user_tz":480,"elapsed":491,"user":{"displayName":"Dom Brugioni","userId":"06247475919080234840"}},"outputId":"40de887f-4076-450d-b9f4-463829e348fc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Data has been written to tweet_IDs.csv\n"]}]},{"cell_type":"code","source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","import urllib3\n","import time\n","\n","# Disable SSL certificate verification warnings\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","def scrape_nitter_from_csv(csv_file):\n","    nitter_instances = [\n","        \"https://scraped-knees.com\"\n","        # Add more Nitter instances from the provided list as needed\n","    ]\n","\n","    for instance in nitter_instances:\n","        print(f\"Trying Nitter instance: {instance}\")\n","        success = scrape_nitter_tweets(instance, csv_file)\n","        if success:\n","            break\n","        else:\n","            print(f\"Failed with instance: {instance}. Retrying...\")\n","\n","def scrape_nitter_tweets(nitter_instance, csv_file):\n","    with open(csv_file, 'r', newline='', encoding='utf-8') as csvfile:\n","        reader = csv.DictReader(csvfile)\n","        for row in reader:\n","            tweet_id = row['tweet_id']\n","            success = scrape_nitter_tweet(nitter_instance, tweet_id)\n","            if not success:\n","                return False\n","            # Delay before scraping the next tweet (to avoid overloading the instance)\n","            time.sleep(10)  # Add a delay of 1 second between requests\n","    return True\n","\n","def scrape_nitter_tweet(nitter_instance, tweet_id):\n","    base_url = f\"{nitter_instance}/twitter/status/\"\n","    url = base_url + str(tweet_id)\n","    try:\n","        response = requests.get(url, verify=False, timeout=10)  # Disable SSL certificate verification\n","        if response.status_code == 200:\n","            soup = BeautifulSoup(response.text, 'html.parser')\n","            # Example: Scraping the tweet text\n","            tweet_text = soup.find('div', class_='tweet-text').text.strip()\n","            print(\"Tweet ID:\", tweet_id)\n","            print(\"Tweet Text:\", tweet_text)\n","            print(\"-\" * 50)\n","            return True\n","        else:\n","            print(f\"Failed to fetch tweet ID {tweet_id} from {nitter_instance}. Status code: {response.status_code}\")\n","            return False\n","    except Exception as e:\n","        print(f\"An error occurred while fetching tweet ID {tweet_id} from {nitter_instance}: {e}\")\n","        return False\n","\n","if __name__ == \"__main__\":\n","    # Replace 'tweet_info.csv' with the path to your CSV file containing tweet IDs\n","    csv_file = 'tweet_IDs.csv'\n","    scrape_nitter_from_csv(csv_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xr-AYasgnOfa","executionInfo":{"status":"ok","timestamp":1709518411728,"user_tz":480,"elapsed":729,"user":{"displayName":"Dom Brugioni","userId":"06247475919080234840"}},"outputId":"c5c70c17-5486-40f2-e6ff-724778c39656"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Trying Nitter instance: https://scraped-knees.com\n","An error occurred while fetching tweet ID 1758594167708832194 from https://scraped-knees.com: 'NoneType' object has no attribute 'text'\n","Failed with instance: https://scraped-knees.com. Retrying...\n"]}]}]}